{
	"cells": [
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python"
				}
			},
			"outputs": [],
			"source": [
				"# Adding required libraries and extra jars to the job -   # <------- PLEASE REPLACE ${BUCKET_NAME} BELOW!!!\n",
				"\n",
				"%extra_py_files s3://glueworkshop-123456789012-us-east-2/library/pycountry_convert.zip\n",
				"%extra_jars s3://crawler-public/json/serde/json-serde.jar\n",
				"\n",
				"# Adding required properties to the job - # <------- PLEASE REPLACE ${BUCKET_NAME} BELOW!!!\n",
				"\n",
				"%%configure \n",
				"{\n",
				"  \"--enable-spark-ui\": \"true\",\n",
				"  \"--spark-event-logs-path\": \"s3://glueworkshop-123456789012-us-east-2/output/lab3/sparklog/\",\n",
				"  \"max_retries\": \"0\"         \n",
				"}"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"editable": true,
				"trusted": true,
				"vscode": {
					"languageId": "python"
				}
			},
			"outputs": [],
			"source": [
				"#Importing all the basic Glue, Spark libraries \n",
				"\n",
				"import sys\n",
				"from awsglue.transforms import *\n",
				"from awsglue.utils import getResolvedOptions\n",
				"from pyspark.context import SparkContext\n",
				"from awsglue.context import GlueContext\n",
				"from awsglue.dynamicframe import DynamicFrame\n",
				"from awsglue.job import Job\n",
				"\n",
				"# Important further required libraries\n",
				"\n",
				"from pyspark.sql.functions import udf, col\n",
				"from pyspark.sql.types import IntegerType, StringType\n",
				"from pyspark import SparkContext\n",
				"from pyspark.sql import SQLContext\n",
				"from datetime import datetime\n",
				"\n",
				"# Starting Spark/Glue Context\n",
				"\n",
				"sc = SparkContext.getOrCreate()\n",
				"glueContext = GlueContext(sc)\n",
				"spark = glueContext.spark_session\n",
				"job = Job(glueContext)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python"
				}
			},
			"outputs": [],
			"source": [
				"# Important pycountry_convert function from the external python library (pycountry_convert.zip)\n",
				"\n",
				"from pycountry_convert import (\n",
				"    convert_country_alpha2_to_country_name,\n",
				"    convert_country_alpha2_to_continent,\n",
				"    convert_country_name_to_country_alpha2,\n",
				"    convert_country_alpha3_to_country_alpha2,\n",
				")\n",
				"\n",
				"\n",
				"# Defining the function code\n",
				"def get_country_code2(country_name):\n",
				"    country_code2 = 'US'\n",
				"    try:\n",
				"        country_code2 = convert_country_name_to_country_alpha2(country_name)\n",
				"    except KeyError:\n",
				"        country_code2 = ''\n",
				"    return country_code2\n",
				"\n",
				"# leveraging the Country Code UDF\n",
				"\n",
				"udf_get_country_code2 = udf(lambda z: get_country_code2(z), StringType())\n",
				"\n",
				"\n",
				"# Reading the dataset into a DataFrame\n",
				"s3_bucket = \"s3://glueworkshop-123456789012-us-east-2/\"                              # <------- PLEASE REPLACE ONLY THE ${BUCKET_NAME} HERE (Keep the \"s3://\" and the final \"/\" part)!!!\n",
				"job_time_string = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
				"\n",
				"df = spark.read.load(s3_bucket + \"input/lab2/sample.csv\", \n",
				"                     format=\"csv\", \n",
				"                     sep=\",\", \n",
				"                     inferSchema=\"true\", \n",
				"                     header=\"true\")\n",
				"\n",
				"# Performing a transformation that adds a new Country Code column to the dataframe based on the Country Code UDF output\n",
				"\n",
				"new_df = df.withColumn('country_code_2', udf_get_country_code2(col(\"country\")))"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"trusted": true,
				"vscode": {
					"languageId": "python"
				}
			},
			"outputs": [],
			"source": [
				"# Sinking the data into another S3 bucket path\n",
				"\n",
				"new_df.write.csv(s3_bucket + \"/output/lab3/notebook/\" + job_time_string + \"/\")"
			]
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Glue PySpark",
			"language": "python",
			"name": "glue_pyspark"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "Python_Glue_Session",
			"pygments_lexer": "python3"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 4
}
